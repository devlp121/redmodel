{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Data Loading and Preprocessing\n",
    "\n",
    "Data source from `Dreaddit: A Reddit Dataset for Stress Analysis in Social Media`.\n",
    "\n",
    "Following tasks are undertaken:\n",
    "* Columns Selection\n",
    "* Feature Transformation\n",
    "* Handling Missing Values\n",
    "* Column Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data Encoding, Feature Selection and Training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext lab_black\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data import\n",
    "dreaddit_train_df = pd.read_csv(\"../data/unprocessed/dreaddit-train.csv\")\n",
    "dreaddit_test_df = pd.read_csv(\"../data/unprocessed/dreaddit-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_id</th>\n",
       "      <th>sentence_range</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>social_timestamp</th>\n",
       "      <th>social_karma</th>\n",
       "      <th>syntax_ari</th>\n",
       "      <th>...</th>\n",
       "      <th>lex_dal_min_pleasantness</th>\n",
       "      <th>lex_dal_min_activation</th>\n",
       "      <th>lex_dal_min_imagery</th>\n",
       "      <th>lex_dal_avg_activation</th>\n",
       "      <th>lex_dal_avg_imagery</th>\n",
       "      <th>lex_dal_avg_pleasantness</th>\n",
       "      <th>social_upvote_ratio</th>\n",
       "      <th>social_num_comments</th>\n",
       "      <th>syntax_fk_grade</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>8601tu</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>33181</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1521614353</td>\n",
       "      <td>5</td>\n",
       "      <td>1.806818</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.77000</td>\n",
       "      <td>1.52211</td>\n",
       "      <td>1.89556</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>3.253573</td>\n",
       "      <td>-0.002742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistance</td>\n",
       "      <td>8lbrx9</td>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>2606</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1527009817</td>\n",
       "      <td>4</td>\n",
       "      <td>9.429737</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.69586</td>\n",
       "      <td>1.62045</td>\n",
       "      <td>1.88919</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2</td>\n",
       "      <td>8.828316</td>\n",
       "      <td>0.292857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>9ch1zh</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>38816</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1535935605</td>\n",
       "      <td>2</td>\n",
       "      <td>7.769821</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.1429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.83088</td>\n",
       "      <td>1.58108</td>\n",
       "      <td>1.85828</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>7.841667</td>\n",
       "      <td>0.011894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7rorpp</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1516429555</td>\n",
       "      <td>0</td>\n",
       "      <td>2.667798</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.75356</td>\n",
       "      <td>1.52114</td>\n",
       "      <td>1.98848</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>4.104027</td>\n",
       "      <td>0.141671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>survivorsofabuse</td>\n",
       "      <td>9p2gbc</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1421</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1539809005</td>\n",
       "      <td>24</td>\n",
       "      <td>7.554238</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.77644</td>\n",
       "      <td>1.64872</td>\n",
       "      <td>1.81456</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>7.910952</td>\n",
       "      <td>-0.204167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit post_id sentence_range  \\\n",
       "0              ptsd  8601tu       (15, 20)   \n",
       "1        assistance  8lbrx9         (0, 5)   \n",
       "2              ptsd  9ch1zh       (15, 20)   \n",
       "3     relationships  7rorpp        [5, 10]   \n",
       "4  survivorsofabuse  9p2gbc         [0, 5]   \n",
       "\n",
       "                                                text     id  label  \\\n",
       "0  He said he had not felt that way before, sugge...  33181      1   \n",
       "1  Hey there r/assistance, Not sure if this is th...   2606      0   \n",
       "2  My mom then hit me with the newspaper and it s...  38816      1   \n",
       "3  until i met my new boyfriend, he is amazing, h...    239      1   \n",
       "4  October is Domestic Violence Awareness Month a...   1421      1   \n",
       "\n",
       "   confidence  social_timestamp  social_karma  syntax_ari  ...  \\\n",
       "0         0.8        1521614353             5    1.806818  ...   \n",
       "1         1.0        1527009817             4    9.429737  ...   \n",
       "2         0.8        1535935605             2    7.769821  ...   \n",
       "3         0.6        1516429555             0    2.667798  ...   \n",
       "4         0.8        1539809005            24    7.554238  ...   \n",
       "\n",
       "   lex_dal_min_pleasantness  lex_dal_min_activation  lex_dal_min_imagery  \\\n",
       "0                     1.000                  1.1250                  1.0   \n",
       "1                     1.125                  1.0000                  1.0   \n",
       "2                     1.000                  1.1429                  1.0   \n",
       "3                     1.000                  1.1250                  1.0   \n",
       "4                     1.000                  1.1250                  1.0   \n",
       "\n",
       "   lex_dal_avg_activation  lex_dal_avg_imagery  lex_dal_avg_pleasantness  \\\n",
       "0                 1.77000              1.52211                   1.89556   \n",
       "1                 1.69586              1.62045                   1.88919   \n",
       "2                 1.83088              1.58108                   1.85828   \n",
       "3                 1.75356              1.52114                   1.98848   \n",
       "4                 1.77644              1.64872                   1.81456   \n",
       "\n",
       "   social_upvote_ratio  social_num_comments  syntax_fk_grade  sentiment  \n",
       "0                 0.86                    1         3.253573  -0.002742  \n",
       "1                 0.65                    2         8.828316   0.292857  \n",
       "2                 0.67                    0         7.841667   0.011894  \n",
       "3                 0.50                    5         4.104027   0.141671  \n",
       "4                 1.00                    1         7.910952  -0.204167  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dreaddit_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think he doesn't want to put in the effort for the relationship to work (and we're both so difficult that we have to work on our relationships, doesn't matter with whom) but he can't be without me either. What should I do? I'm afraid this is gonna happen over and over again, because I'm always forgiving him at some point. Am I being strung along? TL;DR: Boyfriend [28,M] broke up with me [23,F] after on-off for 1.5 years, I thought we just got it together and am devastated...don't know what to do, want to keep fighting but should I?\n"
     ]
    }
   ],
   "source": [
    "print(dreaddit_train_df.text[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def preprocess(ReviewText):\n",
    "#    ReviewText = ReviewText.str.replace(\"(<br/>)\", \"\")\n",
    "#    ReviewText = ReviewText.str.replace('(<a).*(>).*(</a>)', '')\n",
    "#    ReviewText = ReviewText.str.replace('(&amp)', '')\n",
    "#    ReviewText = ReviewText.str.replace('(&gt)', '')\n",
    "#    ReviewText = ReviewText.str.replace('(&lt)', '')\n",
    "#    ReviewText = ReviewText.str.replace('(\\xa0)', ' ')  \n",
    "#    return ReviewText\n",
    "#df['Review Text'] = preprocess(dreaddit_train_df['Review Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = dreaddit_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\n",
    "    \"text\",\n",
    "    \"label\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  He said he had not felt that way before, sugge...      1\n",
       "1  Hey there r/assistance, Not sure if this is th...      0\n",
       "2  My mom then hit me with the newspaper and it s...      1\n",
       "3  until i met my new boyfriend, he is amazing, h...      1\n",
       "4  October is Domestic Violence Awareness Month a...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = dreaddit_train_df[new_cols]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 715 entries, 0 to 714\n",
      "Columns: 116 entries, id to sentiment\n",
      "dtypes: float64(107), int64(5), object(4)\n",
      "memory usage: 648.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Its like that, if you want or not.“ ME: I have...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I man the front desk and my title is HR Custom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We'd be saving so much money with this new hou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My ex used to shoot back with \"Do you want me ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I haven’t said anything to him yet because I’m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Its like that, if you want or not.“ ME: I have...      0\n",
       "1  I man the front desk and my title is HR Custom...      0\n",
       "2  We'd be saving so much money with this new hou...      1\n",
       "3  My ex used to shoot back with \"Do you want me ...      1\n",
       "4  I haven’t said anything to him yet because I’m...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cols = dreaddit_test_df.columns\n",
    "dreaddit_test_df.info()\n",
    "test_df = dreaddit_test_df[new_cols]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2838 entries, 0 to 2837\n",
      "Data columns (total 2 columns):\n",
      "text     2838 non-null object\n",
      "label    2838 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 44.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1488\n",
       "0    1350\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. TF Feature Columns to Classify Structure Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an input pipeline using tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"label\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dataframe, labels))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = df_to_dataset(train_df)\n",
    "test_ds = df_to_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    train_ds.shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "test_dataset = test_ds.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 1), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE\n",
    ")\n",
    "encoder.adapt(train_ds.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'i', 'to', 'and', 'the', 'a', 'my', 'of', 'me',\n",
       "       'that', 'in', 'it', 'for', 'was', 'is', 'but', 'have', 'with',\n",
       "       'this'], dtype='<U13')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [[b'I\\xe2\\x80\\x99m an army reserve officer who has 6.5 years of service. I have a VA disability rating of 40% due to PTSD/Anxiety/depression and ringing in my ears from a tour in Afghanistan. I recently applied to go into the IRR and was turned down. I have been told that I\\xe2\\x80\\x99m not deployable due to my mental health, but I don\\xe2\\x80\\x99t think this was at all mentioned in my IRR packet. just moved for a job in DC and my old unit is now too far to travel to.']]\n",
      "\n",
      "labels:  [0]\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "    print(\"texts: \", example.numpy()[:1])\n",
    "    print()\n",
    "    print(\"labels: \", label.numpy()[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 88,  60,   1,   1,   1,  76,  57,   1,  83,   8, 861,   2,  17,\n",
       "          6,   1,   1,   1,   8,   1, 319,   3,   1,   4,   1,  11,   7,\n",
       "          1,  50,   6,   1,  11,   1,   2, 280,   1,   3,  73, 106,   5,\n",
       "          1,   4,  14, 499, 151,   2,  17,  45, 114,  10,  88,  28,   1,\n",
       "        319,   3,   7, 296, 286,  16,   2, 180,  87,  19,  14,  33,  48,\n",
       "        908,  11,   7,   1,   1,  29, 345,  13,   6, 131,  11,   1,   4,\n",
       "          7, 227,   1,  15,  64, 138, 459,   3, 963,   3,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_example = encoder(example)[:1].numpy()\n",
    "encoded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        encoder,\n",
    "        tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00601296]\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"I have been experiencing a depressing mood and my stress levels are rising tremendously. This should indicate something\"\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, save_weights_only=True, verbose=1\n",
    ")\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 175,489\n",
      "Trainable params: 175,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1/45 [..............................] - ETA: 0s - loss: 0.6927 - accuracy: 0.4062WARNING:tensorflow:From /home/tier/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/45 [>.............................] - ETA: 41s - loss: 0.6928 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7505s vs `on_train_batch_end` time: 1.1746s). Check your callbacks.\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.4757WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "45/45 [==============================] - 59s 1s/step - loss: 0.6923 - accuracy: 0.4757 - val_loss: 0.6918 - val_accuracy: 0.4839\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6889 - accuracy: 0.4757\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "45/45 [==============================] - 52s 1s/step - loss: 0.6889 - accuracy: 0.4757\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6744 - accuracy: 0.4789\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "45/45 [==============================] - 51s 1s/step - loss: 0.6744 - accuracy: 0.4789\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5915 - accuracy: 0.6653\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.5915 - accuracy: 0.6653\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5405 - accuracy: 0.7255\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "45/45 [==============================] - 63s 1s/step - loss: 0.5405 - accuracy: 0.7255\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4914 - accuracy: 0.7597\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "45/45 [==============================] - 82s 2s/step - loss: 0.4914 - accuracy: 0.7597\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.7787\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "45/45 [==============================] - 79s 2s/step - loss: 0.4635 - accuracy: 0.7787\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4345 - accuracy: 0.7974\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "45/45 [==============================] - 80s 2s/step - loss: 0.4345 - accuracy: 0.7974\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4230 - accuracy: 0.8062\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "45/45 [==============================] - 81s 2s/step - loss: 0.4230 - accuracy: 0.8062\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3874 - accuracy: 0.8295\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "45/45 [==============================] - 97s 2s/step - loss: 0.3874 - accuracy: 0.8295\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    callbacks=[cp_callback, tensorboard_callback],\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tier/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/tier/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: savedmodel/redmodel/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p savedmodel\n",
    "model.save(\"savedmodel/redmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 3s 219ms/step - loss: 0.5856 - accuracy: 0.7455\n",
      "Test Loss: 0.5856103301048279\n",
      "Test Accuracy: 0.7454545497894287\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print(\"Test Loss: {}\".format(test_loss))\n",
    "print(\"Test Accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5048018]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on a sample to test accuract and padding.\n",
    "\n",
    "sample_text = \"I have been experiencing a depressing mood and my stress levels are rising tremendously. This should indicate something.\"\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ae8cce2ff027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# name of the tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"embedding.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Set up config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logs' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorboard.plugins import projector\n",
    "\n",
    "# Save the weights we want to analyse as a variable. Note that the first\n",
    "# value represents any unknown word, which is not in the metadata, so\n",
    "# we will remove that value.\n",
    "weights = tf.Variable(model.layers[0].get_weights()[0][1:])\n",
    "# Create a checkpoint from embedding, the filename and key are\n",
    "# name of the tensor.\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(logs, \"embedding.ckpt\"))\n",
    "\n",
    "# Set up config\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(logs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7559), started 0:02:53 ago. (Use '!kill 7559' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6d59a39c662e7706\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6d59a39c662e7706\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
